{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviando docs para banco de dados no AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Modulos e conectando com a base via pymysql\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "host = 'database-1.cyvfcyenu8c2.us-east-1.rds.amazonaws.com'\n",
    "port = 3306\n",
    "user = #USER\n",
    "password = #PASSWORD\n",
    "db_name='database-1'\n",
    "\n",
    "cnxn = pymysql.connect(host = host,\n",
    "                       user = user,\n",
    "                       database=db_name,\n",
    "                       password = password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "productid     int64\n",
       "date         object\n",
       "zip           int64\n",
       "units         int64\n",
       "revenue      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tratando o arquivo Vendas csv. Subsitui a string na coluna revenue $ por \"\" \n",
    "#Isso nos deixa tratar o valor como int\n",
    "#Tambem manipulamos a data e deixamops no formato dd/mm/yyyy\n",
    "#Depois salvamos odf manipulado de volta para um novo csv de vendas\n",
    "\n",
    "df = pd.read_csv('dir_local' + '\\vendas.csv',sep=',')\n",
    "df.head()\n",
    "\n",
    "df[\"revenue\"]= df[\"revenue\"].str.replace(\"$\",\"\")\n",
    "df[\"revenue\"]= df[\"revenue\"].str.replace(\",\",\"\")\n",
    "df[\"date\"]= df[\"date\"].str.replace(\"12:00:00 AM\",\"\")\n",
    "df.to_csv('dir_local' + '\\Vendas_new.csv', index=False)  \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porximas celulas irao ler o arquivo e transformaos em dataframes. Cada arquivo representa uma tabela da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fabricante=pd.read_csv('dir_local' + '\\fabricante.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Geo=pd.read_csv('dir_local' + 'geo.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Produto=pd.read_csv('dir_local' + '\\produto.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vendas=pd.read_csv('dir_local' + '\\Vendas_new.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos o cursos da conexao com a base de dados com parametros cnxn aacima\n",
    "mycursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demos um replace nos valores vazios de Revenue por zero. \n",
    "Vendas[\"revenue\"].fillna(0, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As proximas celulas criam as queries utilizadas para subir as tabelas no banco de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_Create_Fabricante='''CREATE TABLE Fabricante(\n",
    "ID INT NOT NULL,\n",
    "manufacturerid INT NOT NULL,\n",
    "manufacturer VARCHAR(255) NULL,\n",
    "PRIMARY KEY (ID)\n",
    ");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_Create_Geo='''CREATE TABLE Geo(\n",
    "zip INT NULL,\n",
    "city VARCHAR(255) NULL,\n",
    "state VARCHAR(255) NULL,\n",
    "region VARCHAR(255) NULL,\n",
    "district VARCHAR(255) NULL\n",
    ");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_Create_Produto='''CREATE TABLE Produto(\n",
    "category varchar(255) NULL,\n",
    "segment varchar(255) NULL,\n",
    "product varchar(255) NULL,\n",
    "productid int NOT NULL,\n",
    "iscompetehide varchar(255) NULL,\n",
    "manufacturerid int NOT NULL,\n",
    "PRIMARY KEY (productid)\n",
    ");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_Create_Vendas='''CREATE TABLE Vendas(\n",
    "productid int  NULL,\n",
    "date varchar(255) NULL,\n",
    "zip varchar(255) NULL,\n",
    "units int  NULL,\n",
    "revenue int NULL\n",
    ");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A linha abaixo cria uma query que drop as tabelas da base de dados se elas ja existirem\n",
    "sql_drop=\"DROP TABLE IF Exists Fabricante,Geo,Produto,Vendas;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O cursor executa a query drop e depois da um commit na base\n",
    "#Isso é necessario pois a conexao nao esta em autocommit\n",
    "mycursor.execute(sql_drop)\n",
    "mycursor.execute('commit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O cursos executa as queries de criaçao das tabelas na base\n",
    "mycursor.execute(sql_Create_Fabricante)\n",
    "mycursor.execute(sql_Create_Produto)\n",
    "mycursor.execute(sql_Create_Geo)\n",
    "mycursor.execute(sql_Create_Vendas)\n",
    "mycursor.execute('commit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=''\n",
    "\n",
    "#Inserting DataFrame records one by one.\n",
    "for i,row in Fabricante.iterrows():\n",
    "        \n",
    "    sql += f'({row[0]}, {row[1]},\"{row[2]}\"),\\n'\n",
    "\n",
    "\n",
    "sql=\"INSERT INTO Fabricante (ID,manufacturerid,manufacturer)\\nVALUES\\n\" + sql[:-2]+\";\"\n",
    "\n",
    "print(sql)\n",
    "\n",
    "mycursor.execute(sql)\n",
    "\n",
    "mycursor.execute('commit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=''\n",
    "\n",
    "#Inserting DataFrame records one by one.\n",
    "for i,row in Geo.iterrows():\n",
    "        \n",
    "    sql += f'({row[0]}, \"{row[1]}\",\"{row[2]}\",\"{row[3]}\",\"{row[4]}\"),\\n'\n",
    "\n",
    "sql=\"INSERT INTO Geo (zip,city,state,region,district)\\nVALUES\\n\" + sql[:-2]+\";\"\n",
    "\n",
    "print(sql)\n",
    "\n",
    "mycursor.execute(sql)\n",
    "\n",
    "mycursor.execute('commit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql=''\n",
    "\n",
    "#Inserting DataFrame records one by one.\n",
    "for i,row in Produto.iterrows():\n",
    "        \n",
    "    sql += f'(\"{row[0]}\", \"{row[1]}\",\"{row[2]}\",{row[3]},\"{row[4]}\",{row[5]}),\\n'\n",
    "\n",
    "\n",
    "sql=\"INSERT INTO Produto (category,segment,product,productid,iscompetehide,manufacturerid)\\nVALUES\\n\" + sql[:-2]+\";\"\n",
    "\n",
    "print(sql)\n",
    "\n",
    "mycursor.execute(sql)\n",
    "\n",
    "mycursor.execute('commit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O for loop abaixo segue a mesma logica das queries acima, porem como a tabela é muito grande precisamos \n",
    "#executa-la em pedaços. Para isso utilizamos um contador que zera as linhas da query a cada 10000 linhas\n",
    "#Em outras palavras inserimos queries de 10k de linhas por \"iteraçao\" do contador count. \n",
    "\n",
    "count=1\n",
    "\n",
    "sql=''\n",
    "#Inserting DataFrame records one by one.\n",
    "for i,row in Vendas.iterrows():\n",
    "        \n",
    "    sql += f'({row[0]}, \"{row[1]}\",\"{row[2]}\",{row[3]},{row[4]}),\\n'\n",
    "    \n",
    "    if i==10000*count:\n",
    "    \n",
    "        sql=\"INSERT INTO Vendas (productid,date,zip,units,revenue)\\nVALUES\\n\" + sql[:-2]+\";\"\n",
    "\n",
    "        mycursor.execute(sql)\n",
    "\n",
    "        mycursor.execute('commit')\n",
    "\n",
    "        print(count)\n",
    "\n",
    "        sql=''\n",
    "\n",
    "        count=count+1"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
